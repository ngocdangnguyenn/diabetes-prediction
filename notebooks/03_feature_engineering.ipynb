{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc2dd2e",
   "metadata": {},
   "source": [
    "## Feature Engineering - Diabetes Dataset\n",
    "### Introduction\n",
    "This notebook focuses on **feature engineering** for the diabetes prediction project. Using the cleaned dataset from `02_data_preprocessing.ipynb`, we will create informative features that enhance model performance and interpretability.\n",
    "\n",
    "**Dataset:** Diabetes Dataset (Kaggle)\n",
    "\n",
    "**Objective:** Create and select new features to improve model performance and prepare for modeling.\n",
    "\n",
    "**Author:** NGUYEN Ngoc Dang Nguyen - Final-year Student in Computer Science, Aix-Marseille University\n",
    "\n",
    "**Feature Engineering Steps:**\n",
    "1. Import Libraries and Load Data\n",
    "2. Feature Creation\n",
    "3. Feature Transformation\n",
    "4. Encoding Categorical Features\n",
    "5. Feature Selection\n",
    "6. Final Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb46501",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5af376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/cleaned_data.csv\")\n",
    "\n",
    "print(f\"Cleaned dataset loaded: {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(f\"Dataset size: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b17d13",
   "metadata": {},
   "source": [
    "### 2. Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['AgeGroup'] = pd.cut(df['Age'],\n",
    "                            bins=[20, 30, 40, 50, 60, 100],\n",
    "                            labels=['20-29', '30-39', '40-49', '50-59', '60+'],\n",
    "                            right=False)\n",
    "\n",
    "    df['BMI_Category'] = pd.cut(df['BMI'],\n",
    "                                bins=[0, 18.5, 25, 30, 100],\n",
    "                                labels=['Underweight', 'Normal', 'Overweight', 'Obese'],\n",
    "                                right=False)\n",
    "\n",
    "    df['Insulin_Glucose_Ratio'] = df['Insulin'] / df['Glucose'].replace(0, np.nan)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = create_features(df)\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f'Train shape: {X_train.shape}, Test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97143a4d",
   "metadata": {},
   "source": [
    "### 3. Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Pregnancies','Glucose','BloodPressure','SkinThickness',\n",
    "            'Insulin','BMI','DiabetesPedigreeFunction','Age','Insulin_Glucose_Ratio']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5387abf",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df, categories=None):\n",
    "    df_encoded = pd.get_dummies(df, columns=['AgeGroup', 'BMI_Category'], drop_first=True)\n",
    "    \n",
    "    if categories is not None:\n",
    "        missing_cols = set(categories) - set(df_encoded.columns)\n",
    "        for col in missing_cols:\n",
    "            df_encoded[col] = 0\n",
    "        df_encoded = df_encoded[categories]  \n",
    "    return df_encoded\n",
    "\n",
    "X_train_encoded = encode_categorical(X_train)\n",
    "X_test_encoded = encode_categorical(X_test, categories=X_train_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea57a6",
   "metadata": {},
   "source": [
    "### 5. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf.fit(X_train_encoded, y_train)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train_encoded.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances.head(10).plot(kind='barh', color='teal')\n",
    "plt.title(\"Top 10 Feature Importances (Random Forest)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 features:\")\n",
    "print(importances.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153401a4",
   "metadata": {},
   "source": [
    "### 6. Final Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89086c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.to_csv('../data/processed/X_train_final.csv', index=False)\n",
    "X_test_encoded.to_csv('../data/processed/X_test_final.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)\n",
    "print(f\"Final feature set shape: {X_train_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cad6dc",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Feature engineering produced 16 final features by creating categorical bins (AgeGroup, BMI_Category) and a numeric ratio (Insulin_Glucose_Ratio), applying scaling to numeric features, and one-hot encoding categorical variables. RandomForest feature importance analysis identified Glucose, BMI, and Age as the most predictive features. The engineered datasets were saved to `data/processed/` and are ready for model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
